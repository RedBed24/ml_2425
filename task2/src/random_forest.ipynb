{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOELzfsjoAmB"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('../data/training_set_labels.csv')\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/training_set_features.csv')\n",
    "train['h1n1_target'] = label['h1n1_vaccine']\n",
    "train['seasonal_target'] = label['seasonal_vaccine']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test_set_features.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(test['respondent_id'])\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcVGfoVMoAmG"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['respondent_id'], inplace=True)\n",
    "test.drop(columns=['respondent_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding in categorical columns in 0 and 1\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# Transformar True y False en 1 y 0\n",
    "train = train * 1\n",
    "test = test * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar las características más importantes según un Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear un clasificador de Random Forest\n",
    "rf_h1n1 = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf_h1n1.fit(train.drop(['h1n1_target', 'seasonal_target'], axis=1), train['h1n1_target'])\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importances = rf_h1n1.feature_importances_\n",
    "\n",
    "# Crear un DataFrame con las características y su importancia\n",
    "feature_importances = pd.DataFrame({'feature': train.drop(['h1n1_target', 'seasonal_target'], axis=1).columns, 'importance': importances})\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Mostrar las características que sobrepasen un umbral\n",
    "threshold = 0.015\n",
    "selected_features = feature_importances[feature_importances['importance'] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las características en el conjunto de entrenamiento y de prueba\n",
    "train_h1n1 = train[list(selected_features['feature'])+ ['h1n1_target']]\n",
    "test_h1n1 = test[list(selected_features['feature'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar las características más importantes según un Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear un clasificador de Random Forest\n",
    "rf_seasonal = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf_seasonal.fit(train.drop(['h1n1_target', 'seasonal_target'], axis=1), train['seasonal_target'])\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importances = rf_seasonal.feature_importances_\n",
    "\n",
    "# Crear un DataFrame con las características y su importancia\n",
    "feature_importances = pd.DataFrame({'feature': train.drop(['h1n1_target', 'seasonal_target'], axis=1).columns, 'importance': importances})\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Mostrar las características que sobrepasen un umbral\n",
    "threshold = 0.015\n",
    "selected_features = feature_importances[feature_importances['importance'] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las características en el conjunto de entrenamiento y de prueba\n",
    "train_seasonal = train[list(selected_features['feature'])+ ['seasonal_target']]\n",
    "test_seasonal = test[list(selected_features['feature'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar valores nulos con la media para las columnas numéricas\n",
    "train_h1n1 = train_h1n1.fillna(train_h1n1.mode())\n",
    "train_seasonal = train_seasonal.fillna(train_seasonal.mode())\n",
    "test_h1n1 = test_h1n1.fillna(test_h1n1.mode())\n",
    "test_seasonal = test_seasonal.fillna(test_seasonal.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_h1n1 = train_h1n1.drop(['h1n1_target'], axis=1)\n",
    "X_train_seasonal = train_seasonal.drop(['seasonal_target'], axis=1)\n",
    "y_train_h1n1 = train_h1n1[['h1n1_target']]\n",
    "y_train_seasonal = train_seasonal[['seasonal_target']]\n",
    "X_test_h1n1 = test_h1n1\n",
    "X_test_seasonal = test_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El tamaño de X_train_h1n1 es: \", X_train_h1n1.shape)   \n",
    "print(\"El tamaño de y_train_h1n1 es: \", y_train_h1n1.shape)\n",
    "print(\"El tamaño de X_test_h1n1 es: \", X_test_h1n1.shape)\n",
    "print(\"El tamaño de X_train_seasonal es: \", X_train_seasonal.shape)\n",
    "print(\"El tamaño de y_train_seasonal es: \", y_train_seasonal.shape)\n",
    "print(\"El tamaño de X_test_seasonal es: \", X_test_seasonal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGI-8BPKoAmJ"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Csn39NnoAmK"
   },
   "source": [
    "### H1N1 Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#X_train_h1n1, X_test_h1n1, y_train_h1n1, y_test_h1n1 = train_test_split(train, y_h1n1_vaccine, test_size=0.2, random_state=42)\n",
    "X_train_h1n1_split, X_test_h1n1_split, y_train_h1n1_split, y_test_h1n1_split = train_test_split(X_train_h1n1, y_train_h1n1, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_h1n1 = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_h1n1.fit(X_train_h1n1_split, y_train_h1n1_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_h1n1 = rf_h1n1.predict_proba(X_test_h1n1_split)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fpr, tpr, thresholds = roc_curve(y_test_h1n1_split, y_test_pred_h1n1)\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "ax.set_title(f\"Roc curve AUC: {roc_auc_score(y_test_h1n1_split, y_test_pred_h1n1)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seasonal_split, X_test_seasonal_split, y_train_seasonal_split, y_test_seasonal_split = train_test_split(X_train_seasonal, y_train_seasonal, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_seasonal = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_seasonal.fit(X_train_seasonal_split, y_train_seasonal_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_seasonal = rf_seasonal.predict_proba(X_test_seasonal_split)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roc curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fpr, tpr, thresholds = roc_curve(y_test_seasonal_split, y_test_pred_seasonal)\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "ax.set_title(f\"Roc curve AUC: {roc_auc_score(y_test_seasonal_split, y_test_pred_seasonal)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h1n1_submission_pred = rf_h1n1.predict_proba(test_h1n1)[:, 1]\n",
    "y_seasonal_submission_pred = rf_seasonal.predict_proba(test_seasonal)[:, 1]\n",
    "\n",
    "submission_df['h1n1_vaccine'] = y_h1n1_submission_pred\n",
    "submission_df['seasonal_vaccine'] = y_seasonal_submission_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
