{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we import all the libraries that we are going to use in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the **.csv** files that contain the information about the features and labels of the training data. We save this in two pandas dataframes which we will call `features` and `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data from the provided files\n",
    "features_path = '../data/training_set_features.csv'\n",
    "labels_path = '../data/training_set_labels.csv'\n",
    "\n",
    "# Read the data into pandas dataframes\n",
    "features = pd.read_csv(features_path)\n",
    "labels = pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, two auxiliary dataframes have been created to store the values of the `H1N1 Vaccine` and the `Seasonal Vaccine`. In addition, we remove the `respondent_id` column from the `features` dataframe because this information acts as noise in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels and features\n",
    "labels_h1n1 = labels['h1n1_vaccine']\n",
    "labels_seasonal = labels['seasonal_vaccine']\n",
    "\n",
    "# Drop the respondent_id column from the features\n",
    "features = features.drop(columns=['respondent_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numeric columns\n",
    "categorical_cols = features.select_dtypes(include=['object']).columns\n",
    "numeric_cols = features.select_dtypes(include=['float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "features_numeric = features[numeric_cols].fillna(features[numeric_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "features_categorical = features[categorical_cols].fillna('most_frequent')\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "features_categorical = pd.get_dummies(features, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([features_numeric, features_categorical], axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H1N1 Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_h1n1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [500, 800, 1000],\n",
    "    \"max_depth\": [10, 20, 30],\n",
    "    \"min_samples_split\": [10, 25, 50],\n",
    "    \"min_samples_leaf\": [5, 10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "model_h1n1 = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probabilities of the classes\n",
    "y_pred_prob = model_h1n1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC AUC\n",
    "auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_seasonal, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [500, 800, 1000],\n",
    "    \"max_depth\": [10, 20, 30],\n",
    "    \"min_samples_split\": [10, 25, 50],\n",
    "    \"min_samples_leaf\": [5, 10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "model_seasonal = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probabilities of the classes\n",
    "y_pred_prob = model_seasonal.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC AUC\n",
    "auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the *test_set_features.csv* that contains the information of the instances that we need to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test_set_features.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataframe to store the predicted data of the probabilities of `H1N1 Vaccine` and `Seasonal Vaccine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(test['respondent_id'])\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we do the same preprocessing on the test data as we have done on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.drop(columns=['respondent_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_categorical_cols = test_features.select_dtypes(include=['object']).columns\n",
    "test_numeric_cols = test_features.select_dtypes(include=['float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "test_features_numeric = test_features[test_numeric_cols].fillna(test_features[test_numeric_cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "test_features_categorical = test_features[test_categorical_cols].fillna('most_frequent')\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "test_features_categorical = pd.get_dummies(test_features, columns=test_categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.concat([test_features_numeric, test_features_categorical], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make the predictions and save them in the `submission_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict h1n1_vaccine\n",
    "h1n1_vaccine = model_h1n1.predict_proba(test_features)[:, 1]\n",
    "\n",
    "# Predict seasonal_vaccine\n",
    "seasonal_vaccine = model_seasonal.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['h1n1_vaccine'] = h1n1_vaccine\n",
    "submission_df['seasonal_vaccine'] = seasonal_vaccine\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we genarate a csv to upload in the competition page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried different techniques such as outliers removing, imputing missing values with different options but with all of them, we have obtained worse results.\n",
    "\n",
    "The current solution is a simple one and uses quite straightforward techniques but it is the one that has given us the best score.\n",
    "\n",
    "In addition, we have noticed that there seems to be a limit in a score of 0.86 approximately because, despite using a multitude of techniques or models, the results do not really improve and only very small progress is obtained."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
